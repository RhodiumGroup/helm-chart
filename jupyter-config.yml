# This config is based off of the approach used by the Pangeo cloud deployments
# (https://github.com/pangeo-data/pangeo-cloud-federation)
jupyterhub:
  prePuller:
    hook:
      enabled: false
    continuous:
      enabled: false
  singleuser:
    # see https://jupyterhub-kubespawner.readthedocs.io/en/latest/spawner.html for a
    # description of configuration options
    image:
      pullPolicy: 'Always'
      name: rhodium/notebook
      tag: v0.3.0-alpha.1
    startTimeout: 900
    profileList:
      # commenting out stable options b/c not compatible with this gateway-based cluster until they are updated
      # - display_name: "Rhodium:base stable"
      #   description: "This is the stable build of our <a href=\"https://github.com/RhodiumGroup/docker_images/tree/v0.3.0-alpha.1\">default notebook</a>. Use this if you're not sure."
      # - display_name: "Rhodium: base stable (large)"
      #   description: "Larger notebook allowance, with known stable build of <a href=\"https://github.com/RhodiumGroup/docker_images/tree/v0.3.0-alpha.1\">default notebook</a>"
      #   kubespawner_override:
      #     cpu_limit: 7.5
      #     cpu_guarantee: 7.5
      #     mem_limit: 45G
      #     mem_guarantee: 45G
      - display_name: "Rhodium base: latest"
        description: "This is the version of the notebook deployed on <a href=\"https://github.com/RhodiumGroup/docker_images\">docker_images@gateway</a>. Use this if you want to test out new features!"
        kubespawner_override:
          image: rhodium/notebook:gateway
      - display_name: "Rhodium base: latest (large)"
        description: "Larger notebook allowance, with the latest build of <a href=\"https://github.com/RhodiumGroup/docker_images\">docker_images@gateway</a>"
        kubespawner_override:
          image: rhodium/notebook:gateway
          cpu_limit: 7.5
          cpu_guarantee: 7.5
          mem_limit: 45G
          mem_guarantee: 45G
      # - display_name: 'Coastal: pyTC stable'
      #   description: "Known stable build of <a href=\"https://github.com/RhodiumGroup/docker_images/tree/pyTC-v0.1.0\">rhodium/docker_images@dev-pyTC-base branch</a>"
      #   kubespawner_override:
      #     image: 'rhodium/notebook:pyTC-v0.1.0'
      # - display_name: 'Coastal: pyTC stable (large)'
      #   description: "Larger notebook allowance, with known stable build of <a href=\"https://github.com/RhodiumGroup/docker_images/tree/pyTC-v0.1.0\">rhodium/docker_images@dev-pyTC-base branch</a>"
      #   kubespawner_override:
      #     image: 'rhodium/notebook:pyTC-v0.1.0'
      #     cpu_limit: 7.5
      #     cpu_guarantee: 7.5
      #     mem_limit: 45G
      #     mem_guarantee: 45G
      - display_name: 'Coastal: latest'
        description: "Latest build of <a href=\"https://github.com/RhodiumGroup/docker_images/tree/coastal-gateway\">rhodium/docker_images@coastal-gateway branch</a>"
        kubespawner_override:
          image: 'rhodium/notebook:coastal-gateway'
      - display_name: "Coastal: latest (large)"
        description: "Larger notebook allowance, with the latest build of <a href=\"https://github.com/RhodiumGroup/docker_images/tree/coastal-gateway\">rhodium/docker_images@coastal-gateway branch</a>"
        kubespawner_override:
          image: 'rhodium/notebook:coastal-gateway'
          cpu_limit: 7.5
          cpu_guarantee: 7.5
          mem_limit: 45G
          mem_guarantee: 45G
    storage:
      capacity: 10Gi
      dynamic:
        # storageClass: ssd
        storageClass: standard
    cpu:
      limit: 3.75
      guarantee: 3.75
    memory:
      limit: 22.5G
      guarantee: 22.5G
    cloudMetadata:
      enabled: true
  hub:
    resources:
      requests:
        cpu: "0.25"
        memory: 0.5Gi
      limits:
        cpu: "1.25"
        memory: 1Gi
    extraConfig:
      customPodHook: |
            # runs container in privileged mode for FUSE mount access
            from kubernetes import client
            def modify_pod_hook(spawner, pod):
                pod.spec.containers[0].security_context = client.V1SecurityContext(
                    privileged=True,
                    capabilities=client.V1Capabilities(
                        add=['SYS_ADMIN']
                    )
                )
                return pod
            c.KubeSpawner.modify_pod_hook = modify_pod_hook
            c.JupyterHub.logo_file = '/usr/local/share/jupyterhub/static/custom/images/logo.png'
            c.JupyterHub.template_paths = ['/usr/local/share/jupyterhub/custom_templates/']
    extraVolumes:
      - name: custom-templates
        gitRepo:
          repository: "https://github.com/RhodiumGroup/rhodium-custom-jupyterhub-templates.git"
    extraVolumeMounts:
      - mountPath: /usr/local/share/jupyterhub/custom_templates
        name: custom-templates
        subPath: "rhodium-custom-jupyterhub-templates/templates"
      - mountPath: /usr/local/share/jupyterhub/static/custom
        name: custom-templates
        subPath: "rhodium-custom-jupyterhub-templates/assets"
    services:
      dask-gateway:
        apiToken: OVERRIDEME
  scheduling:
    userScheduler:
      enabled: true
    userPlaceholder:
      enabled: false
    userPods:
      nodeAffinity:
        matchNodePurpose: require
    corePods:
      nodeAffinity:
        matchNodePurpose: require
  cull:
    timeout: 259200

  proxy:
    secretToken: OVERRIDEME
    https:
      letsencrypt:
        contactEmail: mdelgado@rhg.com

  auth:
    type: github
    scopes:
      - "read:user"
    orgWhitelist:
      - RhodiumGroup
    admin:
      access: true
      users:
        - bolliger32
        - brews
        - delgadom
        - dgergel
        - mattgoldklang
    whitelist:
      users:
        - dpa9694
        - njdepsky

dask-gateway:
  gateway:
    backend:
      scheduler:
        extraPodConfig:
          imagePullPolicy: "Always"
    auth:
      type: jupyterhub
      jupyterhub:
        apiToken: OVERRIDEME
    extraConfig:
      optionHandler: |
        from dask_gateway_server.options import Options, String, Select, Mapping

        def cluster_options(user):

            # A mapping from profile name to configuration overrides
            standard_cores = 1.8
            standard_mem = 12.7
            scaling_factors = {
                "micro": 0.5,
                "standard": 1,
                "big": 2,
                "giant": 4
            }

            default_tolerations = {
                "0": {
                    "key": "k8s.dask.org_dedicated",
                    "operator": "Equal",
                    "value": "worker",
                    "effect": "NoSchedule"
                }
            }

            def option_handler(options):
                if (":" not in options.worker_image) or (":" not in options.scheduler_image):
                    raise ValueError("When specifying an image you must also provide a tag")
                extra_annotations = {
                    "hub.jupyter.org/username": user.name
                }
                extra_labels = {
                    "hub.jupyter.org/username": user.name,
                    **options.extra_worker_labels
                }
                
                this_env = options.env_items

                # add extra pip packages to be picked up by prepare.sh
                if options.extra_pip_packages != "":
                    this_env["EXTRA_PIP_PACKAGES"] = options.extra_pip_packages

                # add gcsfuse Tokens
                this_env["GCSFUSE_TOKENS"] = options.gcsfuse_tokens

                # add google cloud auth
                this_env["GOOGLE_APPLICATION_CREDENTIALS"] = f"/opt/gcsfuse_tokens/{options.cred_name}.json"

                return {
                    "worker_cores": scaling_factors[options.profile] * standard_cores,
                    "worker_memory": f"{scaling_factors[options.profile] * standard_mem:.2f}G",
                    # setting images separately here to get a light-weight scheduler
                    "worker_extra_container_config": {
                        "image": options.worker_image,
                        "imagePullPolicy": "Always",
                        "securityContext": {
                          "privileged": True # allows gcsfuse mount
                        }
                    },
                    "scheduler_extra_container_config": {
                        "image": options.scheduler_image,
                        "imagePullPolicy": "Always",
                    },
                    "worker_extra_pod_annotations": extra_annotations,
                    "worker_extra_pod_config": {
                        "tolerations": list(options.worker_tolerations.values())
                    },
                    "worker_extra_pod_labels": extra_labels,
                    "scheduler_extra_pod_annotations": extra_annotations,
                    "scheduler_extra_pod_labels": extra_labels,
                    "environment": this_env,
                    "idle_timeout": 3600*6 # 6 hour idle timeout
                }
            return Options(
                Select(
                    "profile",
                    ["micro", "standard", "big", "giant"],
                    default="standard",
                    label="Cluster Profile"
                ),
                String("worker_image", default="rhodium/worker:gateway", label="Worker Image"),
                String("scheduler_image", default="rhodium/scheduler:gateway", label="Scheduler Image"),
                String("extra_pip_packages", default="", label="Extra pip Packages"),
                String("gcsfuse_tokens", default="", label="GCSFUSE Tokens"),
                String("cred_name", default="rhg-data", label="Bucket for Google Cloud Creds"),
                Mapping("worker_tolerations", default=default_tolerations, label="Worker Pod Tolerations"),
                Mapping("extra_worker_labels", default={}, label="Extra Worker Pod Labels"),
                Mapping("env_items", default={}, label="Environment Variables"),
                handler=option_handler,
            )
        c.Backend.cluster_options = cluster_options